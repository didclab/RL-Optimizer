{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3dcec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileData import *\n",
    "code_path = \"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9587108",
   "metadata": {},
   "outputs": [],
   "source": [
    "requiredFields = ['FileCount', 'AvgFileSize', 'BufSize', 'Bandwidth', 'AvgRtt', 'CC_Level', 'P_Level', 'PP_Level',\n",
    "                  'numActiveCores', 'frequency', 'TotalAvgTput', 'TotalEnergy', 'DataTransferEnergy']\n",
    "LabelName = 'TotalAvgTput'\n",
    "fileData_chameleon = ReadFile(code_path + '/Dataset/Chameleon_Combined_all.csv', requiredFields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec81461c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n",
      "[(32, 34.9238114, 40, 10, 30), (32, 34.9238114, 40, 10, 40), (32, 34.9238114, 40, 10, 50), (32, 222.6392977, 40, 10, 30), (32, 222.6392977, 40, 10, 40), (32, 222.6392977, 40, 10, 50), (32, 222.6392977, 40, 10, 60), (32, 222.64, 40, 10, 30), (32, 222.64, 40, 10, 40), (32, 222.64, 40, 10, 50), (32, 222.64, 40, 10, 60), (32, 222.64, 40, 10, 70), (32, 222.64, 40, 10, 80), (32, 222.64, 40, 10, 90), (64, 222.6343047, 40, 10, 30), (64, 222.6343047, 40, 10, 40), (64, 222.6343047, 40, 10, 60), (128, 222.7841896, 40, 10, 30), (128, 222.7841896, 40, 10, 40), (250, 2.410113346, 40, 10, 30), (250, 2.410113346, 40, 10, 40), (250, 2.410113346, 40, 10, 50), (250, 2.410113346, 40, 10, 60), (250, 2.410113346, 40, 10, 70), (250, 2.410113346, 40, 10, 80), (250, 2.410113346, 40, 10, 90), (500, 0.098544573, 40, 10, 30), (500, 0.098544573, 40, 10, 40), (500, 100.91, 40, 10, 30), (500, 100.91, 40, 10, 40), (500, 100.91, 40, 10, 50), (500, 100.91, 40, 10, 70), (500, 100.91, 40, 10, 80), (500, 100.91, 40, 10, 90), (2500, 2.40051372, 40, 10, 30), (2500, 2.40051372, 40, 10, 40), (2500, 2.40051372, 40, 10, 50), (10000, 0.099238106, 40, 10, 30)] 38\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "       Bandwidth  FileCount  AvgFileSize  BufSize  CC_Level  P_Level  \\\n",
      "23385         10         32    34.923811       40        16        1   \n",
      "23386         10         32    34.923811       40        16        1   \n",
      "23413         10         32    34.923811       40        16        1   \n",
      "23419         10         32    34.923811       40        16        1   \n",
      "23516         10         32    34.923811       40        32        1   \n",
      "23523         10         32    34.923811       40        32        1   \n",
      "\n",
      "       PP_Level  numActiveCores  frequency  AvgRtt  TotalAvgTput  TotalEnergy  \\\n",
      "23385         8              16        1.2      40   7588.151524      936.915   \n",
      "23386         8              16        1.6      40   7955.841507     1088.349   \n",
      "23413        16              32        1.2      40   7788.906738     1085.162   \n",
      "23419        16              48        2.0      40   7623.967521     1110.996   \n",
      "23516         4              48        2.3      40   7459.346156     1164.332   \n",
      "23523         8               4        2.0      40   7127.523125     1104.584   \n",
      "\n",
      "       DataTransferEnergy  \n",
      "23385          231.457879  \n",
      "23386          415.410093  \n",
      "23413          397.800414  \n",
      "23419          408.763826  \n",
      "23516          446.602165  \n",
      "23523          353.529714  \n"
     ]
    }
   ],
   "source": [
    "optimal_throughput_dictionary_chameleon = fileData_chameleon.return_map_for_tuple_to_throughput()\n",
    "filedata_grouped_df = fileData_chameleon.get_grouped_df()\n",
    "print(type(filedata_grouped_df))\n",
    "filedata_keys=[key for key, _ in filedata_grouped_df]\n",
    "print(filedata_keys,len(filedata_keys))\n",
    "\n",
    "a_group=filedata_grouped_df.get_group(filedata_keys[1])\n",
    "print(type(a_group))\n",
    "print(a_group)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca28e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class environmentGroups:\n",
    "    def __init__(self,\n",
    "                filedata_grouped_df,groupKey,minimum_log_number):\n",
    "                self.logs=[]\n",
    "                self.grouped_df=filedata_grouped_df\n",
    "                self.grouping_list_name=['CC_Level','P_Level','PP_Level']\n",
    "                self.a_group = pd.DataFrame()\n",
    "                self.action_list=[]\n",
    "                self.key_state_dictionary={}\n",
    "                self.key_max_throughput_dictionary={}\n",
    "                self.key_max_throughput_parameters={}\n",
    "                self.key_group_identification={}\n",
    "                self.key_group_number_of_rows={}\n",
    "                self.key_group={}\n",
    "                self.action_list=[]\n",
    "                self.key_action_list={}\n",
    "                for key in groupKey:\n",
    "                    self.individual_group=self.grouped_df.get_group(key)\n",
    "                    if self.individual_group.shape[0] >=minimum_log_number:\n",
    "                        self.a_group = pd.concat([self.a_group,self.individual_group], axis=0)\n",
    "                        ###################################\n",
    "                        state_list=[]\n",
    "                        action_list_individual=[]\n",
    "                        self.group_from_grouped_df=self.individual_group.groupby(['CC_Level','P_Level','PP_Level'])#,'numActiveCores','frequency'\n",
    "                        for key_2 in self.group_from_grouped_df.groups.keys():\n",
    "                            action_list_individual.append(key_2)\n",
    "                            self.action_list.append(key_2)\n",
    "                            state_list.append([key[0],key[1],key[2],key[3],key[4],key_2[0],key_2[1],key_2[2]]) #,key[3],key[4]\n",
    "                        self.key_state_dictionary[key]=state_list\n",
    "                        self.key_max_throughput_dictionary[key]=self.individual_group['TotalAvgTput'].max()\n",
    "                        self.key_max_throughput_parameters[key]=max_throughput_to_parameter(self.individual_group,self.individual_group['TotalAvgTput'].max())\n",
    "                        self.key_group_identification[key]=key\n",
    "                        self.key_group_number_of_rows=self.individual_group.shape[0]\n",
    "                        self.key_group[key]=individual_group\n",
    "                        self.key_action_list[key]=action_list_individual\n",
    "                        ####################################\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    input:groupd key with ('FileCount', 'AvgFileSize', 'BufSize', 'Bandwidth', 'AvgRtt')\n",
    "    output:provides the maximum throughput for the class groupkey\n",
    "    \"\"\"\n",
    "\n",
    "    def group_maximum_throughput(self,key):\n",
    "        return self.key_max_throughput_dictionary[key]\n",
    "\n",
    "    \"\"\"\n",
    "    input:groupd key with ('FileCount', 'AvgFileSize', 'BufSize', 'Bandwidth', 'AvgRtt')\n",
    "    output:provides the total number of logs for the class groupkey\n",
    "    \"\"\"\n",
    "    def total_number_of_logs(self,key):\n",
    "        return self.key_group_number_of_rows[key]\n",
    "    \"\"\"\n",
    "    input:groupd key with ('FileCount', 'AvgFileSize', 'BufSize', 'Bandwidth', 'AvgRtt')\n",
    "    output:provides the total dataframe for the class groupkey\n",
    "    \"\"\"\n",
    "\n",
    "    def return_a_group(self,key):\n",
    "        return self.key_group[key]\n",
    "\n",
    "    \"\"\"\n",
    "    input:\n",
    "    output:provides the group of groups (pp,p,cc) name for the class groupkey\n",
    "    \"\"\"\n",
    "\n",
    "    def return_grouping_list_name(self):\n",
    "        return self.grouping_list_name\n",
    "\n",
    "    \"\"\"\n",
    "    input:\n",
    "    output:provides the action list  for the class groupkey\n",
    "    \"\"\"\n",
    "    def return_action_list(self,key):\n",
    "        return self.key_action_list[key]\n",
    "\n",
    "    \"\"\"\n",
    "    input:groupd key with ('FileCount', 'AvgFileSize', 'BufSize', 'Bandwidth', 'AvgRtt')\n",
    "    output:provides the state list  for the class groupkey\n",
    "    \"\"\"\n",
    "    def return_state_list(self,key):\n",
    "        return self.key_state_dictionary[key]\n",
    "\n",
    "    \"\"\"\n",
    "    input: takes a tuple of action key ('CC_Level','P_Level','PP_Level')\n",
    "    output:provides the list of all the throughputs for the class groupkey and\n",
    "           action key ('CC_Level','P_Level','PP_Level')\n",
    "    \"\"\"\n",
    "    def return_group_key_throughput(self,search_key):\n",
    "        result_throughput=[]\n",
    "        log_group=self.group_from_grouped_df.get_group(search_key)\n",
    "        for index, row in log_group.iterrows():\n",
    "            result_throughput.append(row['TotalAvgTput'])\n",
    "        return result_throughput\n",
    "    \"\"\"\n",
    "    input:groupd key with ('FileCount', 'AvgFileSize', 'BufSize', 'Bandwidth', 'AvgRtt')\n",
    "    output:provides the group key as tuple ('FileCount', 'AvgFileSize','BufSize', 'Bandwidth', 'AvgRtt')\n",
    "    \"\"\"\n",
    "    def return_group_identification(self,key):\n",
    "        return self.group_identification\n",
    "\n",
    "    \"\"\"\n",
    "    input:groupd key with ('FileCount', 'AvgFileSize', 'BufSize', 'Bandwidth', 'AvgRtt')\n",
    "    output:provides the group max throughput corresponding CC,P and PP level as a tuple\n",
    "    \"\"\"\n",
    "    def return_group_max_throughput_parameters(self,key):\n",
    "        return self.key_max_throughput_parameters[key]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
